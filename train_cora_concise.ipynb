{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "static-accounting",
      "metadata": {
        "id": "static-accounting"
      },
      "outputs": [],
      "source": [
        "# NN related libraries\n",
        "import torch \n",
        "import torch.nn as nn \n",
        "from torch.optim import Adam\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import sys \n",
        "sys.path.append('./')\n",
        "\n",
        "# from the code \n",
        "from model.GAT import GAT\n",
        "from utils.layers import GAT_layer\n",
        "\n",
        "# data related \n",
        "from torch_geometric.datasets import Planetoid\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "import time\n",
        "import os\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ranking-punishment",
      "metadata": {
        "id": "ranking-punishment",
        "outputId": "966e2e9e-25f6-4f09-d28c-508d8a77bfb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: Cora():\n",
            "======================\n",
            "Number of graphs: 1\n",
            "Number of features: 1433\n",
            "Number of classes: 7\n"
          ]
        }
      ],
      "source": [
        "dataset = Planetoid(root='/tmp/Cora', name='Cora',transform=T.NormalizeFeatures())\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('======================')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beautiful-vatican",
      "metadata": {
        "id": "beautiful-vatican"
      },
      "outputs": [],
      "source": [
        "edge_index=dataset[0].edge_index\n",
        "nodes_features=dataset[0].x\n",
        "nodes_labels=dataset[0].y\n",
        "\n",
        "#parameters_GAT_network={'num_features_per_layer'={}}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10ea7a1a",
      "metadata": {
        "id": "10ea7a1a"
      },
      "source": [
        "## Training the network in the cora dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b9856ba",
      "metadata": {
        "id": "9b9856ba"
      },
      "source": [
        "### First we define the hyperparameters of the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "146396d9",
      "metadata": {
        "id": "146396d9"
      },
      "outputs": [],
      "source": [
        "C=7 # number of classes of the cora dataset\n",
        "params_network={'num_layers':2,\n",
        "               'num_nodes':nodes_features.shape[0],\n",
        "                'num_features_per_layer':[nodes_features.shape[1],8,C],\n",
        "                'num_heads_per_layer':[8,1],\n",
        "                 'num_epochs':500\n",
        "               }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b97ff5f1",
      "metadata": {
        "id": "b97ff5f1"
      },
      "source": [
        "### Divide the dataset in training, validation and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b440cc5",
      "metadata": {
        "id": "7b440cc5",
        "outputId": "9b899a33-aec7-4604-be56-6532fd2b2b89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The training dataset starts in node 0 and comprises 140 nodes\n",
            "The validation dataset starts in node 1708 and comprises 1000 nodes\n",
            "The test dataset starts in node 140 and comprises 500 nodes\n"
          ]
        }
      ],
      "source": [
        "# indices of each set according to the masks given in the dataset (i.e we use the same assignation as in the original paper)\n",
        "training_set_indices=(dataset[0].train_mask).nonzero(as_tuple=False).flatten()\n",
        "test_set_indices=(dataset[0].test_mask).nonzero(as_tuple=False).flatten()\n",
        "val_set_indices=(dataset[0].val_mask).nonzero(as_tuple=False).flatten()\n",
        "print('The training dataset starts in node {:} and comprises {:} nodes'.format(training_set_indices[0].numpy(),training_set_indices.shape[0]))\n",
        "print('The validation dataset starts in node {:} and comprises {:} nodes'.format(test_set_indices[0].numpy(),test_set_indices.shape[0]))\n",
        "print('The test dataset starts in node {:} and comprises {:} nodes'.format(val_set_indices[0].numpy(),val_set_indices.shape[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27a9beae",
      "metadata": {
        "id": "27a9beae"
      },
      "outputs": [],
      "source": [
        "#Extract the labels for the training set\n",
        "nodes_labels_training_set=nodes_labels.index_select(0,training_set_indices)\n",
        "#validation\n",
        "nodes_labels_validation_set=nodes_labels.index_select(0,val_set_indices)\n",
        "#test\n",
        "nodes_labels_test_set=nodes_labels.index_select(0,test_set_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a440ede0",
      "metadata": {
        "id": "a440ede0"
      },
      "source": [
        "Now we have everything we need in order to start the training process. Let's define the model and run the learning process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34d41ea2",
      "metadata": {
        "id": "34d41ea2"
      },
      "outputs": [],
      "source": [
        "model=GAT(params_network['num_layers'],params_network['num_nodes'],params_network['num_features_per_layer'],params_network['num_heads_per_layer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9c92d9b",
      "metadata": {
        "id": "a9c92d9b"
      },
      "outputs": [],
      "source": [
        "# Let's run the training loop \n",
        "def train_gat(params_network,num_epochs=10000,val_lapse=1000,perform_test='True'):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    #device=torch.device('mps')\n",
        "    time_start=time.time()\n",
        "    model_gat=GAT(params_network['num_layers'],params_network['num_nodes'],params_network['num_features_per_layer'],params_network['num_heads_per_layer']).to(device)\n",
        "    \n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model_gat.parameters(), lr=0.01,weight_decay=0.0005) # weight decay corresponds to the L2 penalty, which in the original implementation is chosen to the value we put here\n",
        "    \n",
        "    graph_data=(nodes_features,edge_index)\n",
        "    for epoch in range(num_epochs):\n",
        "        print(epoch)\n",
        "        \n",
        "        model_gat.train() #set model in training mode\n",
        "        \n",
        "        # We do a forward pass of the model and extract the unnormalized logits for the training set \n",
        "        # shape = (N, C) where N is the number of nodes in the split (train/val/test) and C is the number of classes\n",
        "        nodes_unnormalized_out_train = model_gat(graph_data)[0].index_select(0,training_set_indices)\n",
        "        \n",
        "        loss=loss_fn(nodes_unnormalized_out_train,nodes_labels_training_set)\n",
        "        \n",
        "        #Optimizer backward evaluation\n",
        "        \n",
        "        optimizer.zero_grad()  \n",
        "        loss.backward()  \n",
        "        optimizer.step()  \n",
        "        \n",
        "        # Compute the accuracy\n",
        "\n",
        "        # Finds the index of maximum (unnormalized) score for every node and that's the class prediction for that node.\n",
        "        # Compare those to true (ground truth) labels and find the fraction of correct predictions -> accuracy metric.\n",
        "        predictions = torch.argmax(nodes_unnormalized_out_train, dim=-1)\n",
        "        accuracy = torch.sum(torch.eq(predictions, nodes_labels_training_set).long()).item() / len(nodes_labels_training_set)\n",
        "        \n",
        "        #TensorBoard summary writter \n",
        "        writer=SummaryWriter()\n",
        "        \n",
        "        writer.add_scalar('Loss/train',loss.item(),epoch)\n",
        "        writer.add_scalar('Accuracy/train',accuracy,epoch)\n",
        "        \n",
        "        print(f'time elapsed={(time.time()-time_start):.2f} [s]')\n",
        "        print(f'accuracy test={accuracy:.3f}')\n",
        "        if (epoch+1)%val_lapse==0:\n",
        "            with torch.no_grad():\n",
        "                nodes_unnormalized_out_val = model_gat(graph_data)[0].index_select(0,val_set_indices)\n",
        "                loss_val=loss_fn(nodes_unnormalized_out_val,nodes_labels_validation_set)\n",
        "                predictions = torch.argmax(nodes_unnormalized_out_val, dim=-1)\n",
        "                accuracy = torch.sum(torch.eq(predictions, nodes_labels_validation_set).long()).item() / len(nodes_labels_validation_set)\n",
        "        \n",
        "                \n",
        "                writer.add_scalar('Loss/validation',loss_val.item(),epoch)\n",
        "                writer.add_scalar('Accuracy/validation',accuracy,epoch)\n",
        "                print(f'GAT training: time elapsed= {(time.time() - time_start):.2f} [s] | epoch={epoch + 1} | val acc={accuracy}')\n",
        "        \n",
        "    if perform_test:\n",
        "        with torch.no_grad():\n",
        "            nodes_unnormalized_out_test = model_gat(graph_data)[0].index_select(0,test_set_indices)\n",
        "            loss_test=loss_fn(nodes_unnormalized_out_test,nodes_labels_test_set)\n",
        "            predictions = torch.argmax(nodes_unnormalized_out_test, dim=-1)\n",
        "            accuracy = torch.sum(torch.eq(predictions, nodes_labels_test_set).long()).item() / len(nodes_labels_test_set)\n",
        "        print(f'Test accuracy = {test_acc}')\n",
        "    torch.save({'state_dict':model.state_dict},os.path.join(os.path.dirname('model'), 'model','saved_model','model_gat_trained.pt'))\n",
        "    writer.close()\n",
        "        \n",
        "        \n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "633ce58a",
      "metadata": {
        "id": "633ce58a",
        "outputId": "8aa6dad8-acaf-4265-a49e-4dbabfe0b01f"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "The MPS backend is supported on MacOS 12.3+.Current OS version can be queried using `sw_vers`",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_gat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_network\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1001\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[25], line 6\u001b[0m, in \u001b[0;36mtrain_gat\u001b[0;34m(params_network, num_epochs, val_lapse, perform_test)\u001b[0m\n\u001b[1;32m      4\u001b[0m device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m time_start\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 6\u001b[0m model_gat\u001b[38;5;241m=\u001b[39m\u001b[43mGAT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_network\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_layers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparams_network\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_nodes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparams_network\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_features_per_layer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparams_network\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_heads_per_layer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      9\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adam(model_gat\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0005\u001b[39m) \u001b[38;5;66;03m# weight decay corresponds to the L2 penalty, which in the original implementation is chosen to the value we put here\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/ENS/3eme_annee/Deep_learning/project/GAT_env/lib/python3.11/site-packages/torch/nn/modules/module.py:987\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    984\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 987\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/ENS/3eme_annee/Deep_learning/project/GAT_env/lib/python3.11/site-packages/torch/nn/modules/module.py:639\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 639\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    642\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    643\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    644\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    650\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/ENS/3eme_annee/Deep_learning/project/GAT_env/lib/python3.11/site-packages/torch/nn/modules/module.py:639\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 639\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    642\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    643\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    644\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    650\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/ENS/3eme_annee/Deep_learning/project/GAT_env/lib/python3.11/site-packages/torch/nn/modules/module.py:639\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 639\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    642\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    643\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    644\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    650\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/ENS/3eme_annee/Deep_learning/project/GAT_env/lib/python3.11/site-packages/torch/nn/modules/module.py:662\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 662\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    663\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
            "File \u001b[0;32m~/Documents/ENS/3eme_annee/Deep_learning/project/GAT_env/lib/python3.11/site-packages/torch/nn/modules/module.py:985\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    983\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    984\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 985\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The MPS backend is supported on MacOS 12.3+.Current OS version can be queried using `sw_vers`"
          ]
        }
      ],
      "source": [
        "train_gat(params_network,num_epochs=1001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a8bca03",
      "metadata": {
        "id": "2a8bca03",
        "outputId": "5e47624a-6747-4b95-c883-888540172a6b"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'torch' has no attribute 'mps'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmps\u001b[49m\u001b[38;5;241m.\u001b[39mis_available\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'mps'"
          ]
        }
      ],
      "source": [
        "torch.mps.is_available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f8bff03",
      "metadata": {
        "id": "7f8bff03",
        "outputId": "fcaf49ac-c5b0-44bd-95b8-a5e6d4f60675"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'model/saved_model'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.path.join(os.path.dirname('model'), 'model','saved_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b60ca3f",
      "metadata": {
        "id": "7b60ca3f",
        "outputId": "dc6c70cf-e25f-4c74-d57c-6ceecbfafde4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.path.dirname('model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf730140",
      "metadata": {
        "id": "cf730140"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}